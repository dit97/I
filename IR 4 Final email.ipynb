{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# (make sure spam.csv is in your working directory or provide full path)\n",
    "# Example path: r\"C:\\Users\\YourName\\Downloads\\spam.csv\"\n",
    "data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "\n",
    "# Keep only necessary columns (v1 = label, v2 = message)\n",
    "data = data[['v1', 'v2']]\n",
    "data.columns = ['label', 'message']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"Sample data:\")\n",
    "print(data.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Class distribution:\")\n",
    "print(data['label'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels: ham â†’ 0, spam â†’ 1\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data['message']\n",
    "y = data['label']\n",
    "\n",
    "# Split dataset (75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = knn.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.9117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"âœ… Accuracy: {accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1202\n",
      "           1       1.00      0.36      0.53       191\n",
      "\n",
      "    accuracy                           0.91      1393\n",
      "   macro avg       0.95      0.68      0.74      1393\n",
      "weighted avg       0.92      0.91      0.89      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Confusion Matrix:\n",
      "[[1202    0]\n",
      " [ 123   68]]\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”¹ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#[[TP  FP]\n",
    "#[FN  TN]]\n",
    "#TP (True Positive) = 1202 â†’ Model correctly predicted positive class\n",
    "#FP (False Positive) = 0 â†’ Model predicted positive but it was actually negative\n",
    "#FN (False Negative) = 123 â†’ Model predicted negative but it was actually positive\n",
    "#TN (True Negative) = 68 â†’ Model correctly predicted negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
